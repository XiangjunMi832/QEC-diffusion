[multi-device] Using 3 devices.
[multi-device] Adjusting stage1 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage1 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 1/7: stage1 (R1=0, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage1 step 000001] loss=0.409476 acc_masked=0.3712 ler=0.9310 elapsed=84.4s
[stage1 step 001000] loss=0.188793 acc_masked=0.8364 ler=0.5211 elapsed=189.7s
[stage1 step 002000] loss=0.156411 acc_masked=0.8260 ler=0.5479 elapsed=113.4s
[stage1 step 003000] loss=0.161994 acc_masked=0.8355 ler=0.5441 elapsed=112.9s
[stage1 step 004000] loss=0.147954 acc_masked=0.8504 ler=0.5249 elapsed=112.7s
[eval stage1 @ step 004000] loss=0.445850 acc=0.8378 ler=0.7645
[checkpoint] saved model/curriculum_runs/stage1.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage1 step 005000] loss=0.152337 acc_masked=0.8215 ler=0.5862 elapsed=135.7s
[stage1 step 006000] loss=0.135424 acc_masked=0.8425 ler=0.5479 elapsed=112.0s
[stage1 step 007000] loss=0.143828 acc_masked=0.8337 ler=0.5517 elapsed=111.5s
[stage1 step 008000] loss=0.158949 acc_masked=0.8318 ler=0.5862 elapsed=111.3s
[eval stage1 @ step 008000] loss=0.427266 acc=0.8450 ler=0.7385
[checkpoint] saved model/curriculum_runs/stage1.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage1 step 009000] loss=0.119730 acc_masked=0.8535 ler=0.5134 elapsed=113.7s
[stage1 step 010000] loss=0.116387 acc_masked=0.8501 ler=0.5632 elapsed=111.4s
[stage1 step 011000] loss=0.127517 acc_masked=0.8574 ler=0.5057 elapsed=110.9s
[stage1 step 012000] loss=0.097088 acc_masked=0.8887 ler=0.3985 elapsed=112.2s
[eval stage1 @ step 012000] loss=0.356745 acc=0.8832 ler=0.6063
[checkpoint] saved model/curriculum_runs/stage1.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage1 step 013000] loss=0.136215 acc_masked=0.8716 ler=0.4061 elapsed=112.6s
[stage1 step 014000] loss=0.113133 acc_masked=0.8996 ler=0.3218 elapsed=110.8s
[stage1 step 015000] loss=0.136413 acc_masked=0.8910 ler=0.3563 elapsed=110.8s
[stage1 step 016000] loss=0.106904 acc_masked=0.9064 ler=0.3372 elapsed=110.8s
[eval stage1 @ step 016000] loss=0.491628 acc=0.9061 ler=0.5093
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 017000] loss=0.117107 acc_masked=0.9045 ler=0.3180 elapsed=112.2s
[stage1 step 018000] loss=0.094882 acc_masked=0.9275 ler=0.2682 elapsed=110.7s
[stage1 step 019000] loss=0.105565 acc_masked=0.9101 ler=0.2874 elapsed=110.4s
[stage1 step 020000] loss=0.089127 acc_masked=0.9193 ler=0.2720 elapsed=110.8s
[eval stage1 @ step 020000] loss=0.565845 acc=0.9105 ler=0.4833
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 021000] loss=0.107153 acc_masked=0.9243 ler=0.2682 elapsed=112.6s
[stage1 step 022000] loss=0.107539 acc_masked=0.9191 ler=0.2874 elapsed=110.8s
[stage1 step 023000] loss=0.096245 acc_masked=0.9281 ler=0.2031 elapsed=110.8s
[stage1 step 024000] loss=0.094354 acc_masked=0.9280 ler=0.2452 elapsed=110.8s
[eval stage1 @ step 024000] loss=0.559814 acc=0.9171 ler=0.4540
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 025000] loss=0.123221 acc_masked=0.9169 ler=0.2567 elapsed=113.0s
[stage1 step 026000] loss=0.103731 acc_masked=0.9200 ler=0.2490 elapsed=110.2s
[stage1 step 027000] loss=0.105326 acc_masked=0.9263 ler=0.2146 elapsed=110.9s
[stage1 step 028000] loss=0.089315 acc_masked=0.9314 ler=0.2605 elapsed=110.3s
[eval stage1 @ step 028000] loss=0.658741 acc=0.9142 ler=0.4649
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 029000] loss=0.143662 acc_masked=0.8980 ler=0.3027 elapsed=113.8s
[stage1 step 030000] loss=0.099871 acc_masked=0.9236 ler=0.2567 elapsed=110.7s
[stage1 step 031000] loss=0.120763 acc_masked=0.9098 ler=0.2874 elapsed=110.9s
[stage1 step 032000] loss=0.087005 acc_masked=0.9299 ler=0.2337 elapsed=110.8s
[eval stage1 @ step 032000] loss=0.610049 acc=0.9194 ler=0.4479
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 033000] loss=0.102414 acc_masked=0.9329 ler=0.2069 elapsed=112.7s
[stage1 step 034000] loss=0.130535 acc_masked=0.9177 ler=0.2375 elapsed=110.6s
[stage1 step 035000] loss=0.164439 acc_masked=0.8858 ler=0.3142 elapsed=110.6s
[stage1 step 036000] loss=0.119286 acc_masked=0.9126 ler=0.2682 elapsed=110.3s
[eval stage1 @ step 036000] loss=0.599748 acc=0.9209 ler=0.4384
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 037000] loss=0.081387 acc_masked=0.9367 ler=0.2069 elapsed=112.7s
[stage1 step 038000] loss=0.073560 acc_masked=0.9422 ler=0.2184 elapsed=110.5s
[stage1 step 039000] loss=0.089086 acc_masked=0.9326 ler=0.2146 elapsed=110.3s
[stage1 step 040000] loss=0.121349 acc_masked=0.9170 ler=0.2759 elapsed=110.8s
[eval stage1 @ step 040000] loss=0.535786 acc=0.9201 ler=0.4384
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 041000] loss=0.098057 acc_masked=0.9175 ler=0.2414 elapsed=112.9s
[stage1 step 042000] loss=0.101384 acc_masked=0.9260 ler=0.2375 elapsed=110.4s
[stage1 step 043000] loss=0.107134 acc_masked=0.9343 ler=0.2146 elapsed=110.4s
[stage1 step 044000] loss=0.117639 acc_masked=0.9098 ler=0.2644 elapsed=110.0s
[eval stage1 @ step 044000] loss=0.605760 acc=0.9222 ler=0.4323
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 045000] loss=0.079811 acc_masked=0.9374 ler=0.2146 elapsed=112.1s
[stage1 step 046000] loss=0.112948 acc_masked=0.9185 ler=0.2452 elapsed=110.2s
[stage1 step 047000] loss=0.109993 acc_masked=0.9218 ler=0.2337 elapsed=110.2s
[stage1 step 048000] loss=0.122602 acc_masked=0.9190 ler=0.2452 elapsed=110.1s
[eval stage1 @ step 048000] loss=0.593004 acc=0.9234 ler=0.4261
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 049000] loss=0.100698 acc_masked=0.9253 ler=0.2222 elapsed=115.5s
[stage1 step 050000] loss=0.087213 acc_masked=0.9253 ler=0.2452 elapsed=110.0s
[stage1 step 051000] loss=0.093732 acc_masked=0.9276 ler=0.2261 elapsed=110.9s
[stage1 step 052000] loss=0.073774 acc_masked=0.9339 ler=0.2337 elapsed=110.2s
[eval stage1 @ step 052000] loss=0.558554 acc=0.9242 ler=0.4176
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 053000] loss=0.073325 acc_masked=0.9385 ler=0.2299 elapsed=112.1s
[stage1 step 054000] loss=0.126327 acc_masked=0.9220 ler=0.2299 elapsed=110.1s
[stage1 step 055000] loss=0.114139 acc_masked=0.9291 ler=0.2337 elapsed=110.2s
[stage1 step 056000] loss=0.130330 acc_masked=0.9155 ler=0.1992 elapsed=110.1s
[eval stage1 @ step 056000] loss=0.564065 acc=0.9228 ler=0.4256
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 057000] loss=0.123922 acc_masked=0.9092 ler=0.2567 elapsed=112.0s
[stage1 step 058000] loss=0.137247 acc_masked=0.9143 ler=0.2337 elapsed=109.6s
[stage1 step 059000] loss=0.117322 acc_masked=0.9149 ler=0.2414 elapsed=110.3s
[stage1 step 060000] loss=0.127766 acc_masked=0.9293 ler=0.1686 elapsed=110.1s
[eval stage1 @ step 060000] loss=0.576572 acc=0.9251 ler=0.4089
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 061000] loss=0.112601 acc_masked=0.9206 ler=0.2414 elapsed=112.2s
[stage1 step 062000] loss=0.092482 acc_masked=0.9413 ler=0.1648 elapsed=109.6s
[stage1 step 063000] loss=0.093729 acc_masked=0.9233 ler=0.2414 elapsed=111.2s
[stage1 step 064000] loss=0.116037 acc_masked=0.9258 ler=0.1992 elapsed=110.9s
[eval stage1 @ step 064000] loss=0.579788 acc=0.9243 ler=0.4142
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 065000] loss=0.093290 acc_masked=0.9294 ler=0.1954 elapsed=112.3s
[stage1 step 066000] loss=0.091055 acc_masked=0.9308 ler=0.2261 elapsed=110.7s
[stage1 step 067000] loss=0.108008 acc_masked=0.9099 ler=0.2835 elapsed=110.2s
[stage1 step 068000] loss=0.113480 acc_masked=0.9289 ler=0.1762 elapsed=110.0s
[eval stage1 @ step 068000] loss=0.560034 acc=0.9258 ler=0.4115
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 069000] loss=0.098865 acc_masked=0.9196 ler=0.2414 elapsed=111.8s
[stage1 step 070000] loss=0.100883 acc_masked=0.9352 ler=0.2222 elapsed=110.1s
[stage1 step 071000] loss=0.119257 acc_masked=0.9159 ler=0.2452 elapsed=109.8s
[stage1 step 072000] loss=0.118598 acc_masked=0.9198 ler=0.2299 elapsed=109.8s
[eval stage1 @ step 072000] loss=0.551148 acc=0.9253 ler=0.4114
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 073000] loss=0.103998 acc_masked=0.9208 ler=0.2490 elapsed=111.9s
[stage1 step 074000] loss=0.084383 acc_masked=0.9366 ler=0.1992 elapsed=110.1s
[stage1 step 075000] loss=0.091365 acc_masked=0.9335 ler=0.2069 elapsed=110.1s
[stage1 step 076000] loss=0.084934 acc_masked=0.9381 ler=0.2107 elapsed=110.3s
[eval stage1 @ step 076000] loss=0.552315 acc=0.9240 ler=0.4159
[checkpoint] saved model/curriculum_runs/stage1.pickle
[stage1 step 077000] loss=0.104735 acc_masked=0.9268 ler=0.1992 elapsed=111.7s
[stage1 step 078000] loss=0.098273 acc_masked=0.9319 ler=0.1916 elapsed=109.9s
[stage1 step 079000] loss=0.084469 acc_masked=0.9414 ler=0.2222 elapsed=110.4s
[stage1 step 080000] loss=0.096982 acc_masked=0.9414 ler=0.1762 elapsed=110.0s
[eval stage1 @ step 080000] loss=0.542795 acc=0.9253 ler=0.4131
[checkpoint] saved model/curriculum_runs/stage1.pickle
[multi-device] Adjusting stage2 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage2 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 2/7: stage2 (R1=1, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage2 step 000001] loss=0.104424 acc_masked=0.9336 ler=0.2682 elapsed=59.1s
[stage2 step 001000] loss=0.090074 acc_masked=0.9451 ler=0.1992 elapsed=100.3s
[stage2 step 002000] loss=0.094812 acc_masked=0.9451 ler=0.2069 elapsed=100.2s
[stage2 step 003000] loss=0.099453 acc_masked=0.9453 ler=0.1877 elapsed=100.3s
[stage2 step 004000] loss=0.122302 acc_masked=0.9280 ler=0.2414 elapsed=100.5s
[eval stage2 @ step 004000] loss=0.466405 acc=0.9367 ler=0.3674
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 005000] loss=0.113417 acc_masked=0.9311 ler=0.2375 elapsed=108.0s
[stage2 step 006000] loss=0.097910 acc_masked=0.9382 ler=0.2031 elapsed=100.6s
[stage2 step 007000] loss=0.093638 acc_masked=0.9474 ler=0.1724 elapsed=98.9s
[stage2 step 008000] loss=0.066856 acc_masked=0.9562 ler=0.1648 elapsed=98.5s
[eval stage2 @ step 008000] loss=0.473901 acc=0.9373 ler=0.3612
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 009000] loss=0.087488 acc_masked=0.9417 ler=0.1954 elapsed=100.0s
[stage2 step 010000] loss=0.072652 acc_masked=0.9582 ler=0.1609 elapsed=98.2s
[stage2 step 011000] loss=0.077763 acc_masked=0.9563 ler=0.1571 elapsed=98.2s
[stage2 step 012000] loss=0.088228 acc_masked=0.9465 ler=0.1916 elapsed=98.4s
[eval stage2 @ step 012000] loss=0.453971 acc=0.9392 ler=0.3536
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 013000] loss=0.093352 acc_masked=0.9375 ler=0.2299 elapsed=100.6s
[stage2 step 014000] loss=0.087304 acc_masked=0.9450 ler=0.1801 elapsed=98.7s
[stage2 step 015000] loss=0.078917 acc_masked=0.9595 ler=0.1494 elapsed=99.9s
[stage2 step 016000] loss=0.077778 acc_masked=0.9587 ler=0.1571 elapsed=98.3s
[eval stage2 @ step 016000] loss=0.460864 acc=0.9379 ler=0.3615
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 017000] loss=0.106717 acc_masked=0.9423 ler=0.1571 elapsed=101.2s
[stage2 step 018000] loss=0.074230 acc_masked=0.9509 ler=0.1762 elapsed=98.8s
[stage2 step 019000] loss=0.073324 acc_masked=0.9613 ler=0.1686 elapsed=98.4s
[stage2 step 020000] loss=0.100927 acc_masked=0.9359 ler=0.1762 elapsed=98.5s
[eval stage2 @ step 020000] loss=0.468687 acc=0.9387 ler=0.3565
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 021000] loss=0.105425 acc_masked=0.9340 ler=0.2184 elapsed=100.4s
[stage2 step 022000] loss=0.095725 acc_masked=0.9428 ler=0.2069 elapsed=98.5s
[stage2 step 023000] loss=0.076912 acc_masked=0.9555 ler=0.1571 elapsed=98.0s
[stage2 step 024000] loss=0.086693 acc_masked=0.9470 ler=0.1762 elapsed=98.8s
[eval stage2 @ step 024000] loss=0.464691 acc=0.9380 ler=0.3583
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 025000] loss=0.086898 acc_masked=0.9424 ler=0.2184 elapsed=102.6s
[stage2 step 026000] loss=0.125859 acc_masked=0.9144 ler=0.2682 elapsed=100.4s
[stage2 step 027000] loss=0.090088 acc_masked=0.9519 ler=0.1762 elapsed=100.9s
[stage2 step 028000] loss=0.084783 acc_masked=0.9510 ler=0.1801 elapsed=100.8s
[eval stage2 @ step 028000] loss=0.443735 acc=0.9388 ler=0.3527
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 029000] loss=0.080125 acc_masked=0.9547 ler=0.1686 elapsed=102.6s
[stage2 step 030000] loss=0.115782 acc_masked=0.9231 ler=0.2414 elapsed=101.1s
[stage2 step 031000] loss=0.097476 acc_masked=0.9376 ler=0.2222 elapsed=101.0s
[stage2 step 032000] loss=0.084983 acc_masked=0.9474 ler=0.1916 elapsed=100.2s
[eval stage2 @ step 032000] loss=0.447441 acc=0.9394 ler=0.3599
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 033000] loss=0.090899 acc_masked=0.9334 ler=0.2146 elapsed=99.9s
[stage2 step 034000] loss=0.097040 acc_masked=0.9413 ler=0.1992 elapsed=98.6s
[stage2 step 035000] loss=0.087820 acc_masked=0.9511 ler=0.1762 elapsed=98.6s
[stage2 step 036000] loss=0.085643 acc_masked=0.9405 ler=0.1992 elapsed=98.6s
[eval stage2 @ step 036000] loss=0.471907 acc=0.9388 ler=0.3569
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 037000] loss=0.099250 acc_masked=0.9372 ler=0.2222 elapsed=100.5s
[stage2 step 038000] loss=0.097044 acc_masked=0.9402 ler=0.1992 elapsed=98.8s
[stage2 step 039000] loss=0.110936 acc_masked=0.9321 ler=0.2146 elapsed=98.7s
[stage2 step 040000] loss=0.102184 acc_masked=0.9365 ler=0.2184 elapsed=98.6s
[eval stage2 @ step 040000] loss=0.492806 acc=0.9368 ler=0.3638
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 041000] loss=0.111362 acc_masked=0.9355 ler=0.1762 elapsed=100.2s
[stage2 step 042000] loss=0.109147 acc_masked=0.9353 ler=0.2184 elapsed=97.9s
[stage2 step 043000] loss=0.090827 acc_masked=0.9458 ler=0.2184 elapsed=98.3s
[stage2 step 044000] loss=0.097917 acc_masked=0.9407 ler=0.1992 elapsed=98.3s
[eval stage2 @ step 044000] loss=0.472672 acc=0.9381 ler=0.3637
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 045000] loss=0.106167 acc_masked=0.9383 ler=0.2031 elapsed=99.9s
[stage2 step 046000] loss=0.110990 acc_masked=0.9420 ler=0.1839 elapsed=97.7s
[stage2 step 047000] loss=0.084453 acc_masked=0.9502 ler=0.1609 elapsed=98.5s
[stage2 step 048000] loss=0.093035 acc_masked=0.9490 ler=0.1724 elapsed=98.6s
[eval stage2 @ step 048000] loss=0.491416 acc=0.9377 ler=0.3644
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 049000] loss=0.095579 acc_masked=0.9433 ler=0.2031 elapsed=100.2s
[stage2 step 050000] loss=0.087680 acc_masked=0.9519 ler=0.1686 elapsed=98.5s
[stage2 step 051000] loss=0.083185 acc_masked=0.9509 ler=0.1801 elapsed=98.3s
[stage2 step 052000] loss=0.082931 acc_masked=0.9494 ler=0.1839 elapsed=98.1s
[eval stage2 @ step 052000] loss=0.478686 acc=0.9391 ler=0.3548
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 053000] loss=0.129850 acc_masked=0.9315 ler=0.2222 elapsed=99.6s
[stage2 step 054000] loss=0.099419 acc_masked=0.9464 ler=0.1839 elapsed=97.7s
[stage2 step 055000] loss=0.084240 acc_masked=0.9487 ler=0.1954 elapsed=98.3s
[stage2 step 056000] loss=0.105569 acc_masked=0.9336 ler=0.2375 elapsed=98.8s
[eval stage2 @ step 056000] loss=0.470254 acc=0.9393 ler=0.3472
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 057000] loss=0.083200 acc_masked=0.9478 ler=0.1801 elapsed=99.9s
[stage2 step 058000] loss=0.098360 acc_masked=0.9374 ler=0.2146 elapsed=98.3s
[stage2 step 059000] loss=0.079567 acc_masked=0.9531 ler=0.1801 elapsed=98.4s
[stage2 step 060000] loss=0.096507 acc_masked=0.9420 ler=0.1877 elapsed=99.4s
[eval stage2 @ step 060000] loss=0.481311 acc=0.9395 ler=0.3519
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 061000] loss=0.106252 acc_masked=0.9318 ler=0.2146 elapsed=100.8s
[stage2 step 062000] loss=0.083024 acc_masked=0.9591 ler=0.1418 elapsed=98.8s
[stage2 step 063000] loss=0.108479 acc_masked=0.9263 ler=0.2261 elapsed=99.0s
[stage2 step 064000] loss=0.124271 acc_masked=0.9200 ler=0.2414 elapsed=99.2s
[eval stage2 @ step 064000] loss=0.473910 acc=0.9394 ler=0.3577
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 065000] loss=0.107493 acc_masked=0.9409 ler=0.1992 elapsed=100.0s
[stage2 step 066000] loss=0.087961 acc_masked=0.9467 ler=0.1839 elapsed=98.2s
[stage2 step 067000] loss=0.093904 acc_masked=0.9436 ler=0.2031 elapsed=98.3s
[stage2 step 068000] loss=0.090104 acc_masked=0.9386 ler=0.2107 elapsed=98.3s
[eval stage2 @ step 068000] loss=0.495888 acc=0.9380 ler=0.3630
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 069000] loss=0.103426 acc_masked=0.9400 ler=0.1954 elapsed=100.3s
[stage2 step 070000] loss=0.074532 acc_masked=0.9554 ler=0.1724 elapsed=98.4s
[stage2 step 071000] loss=0.104506 acc_masked=0.9393 ler=0.2184 elapsed=98.3s
[stage2 step 072000] loss=0.110764 acc_masked=0.9409 ler=0.1877 elapsed=98.1s
[eval stage2 @ step 072000] loss=0.492285 acc=0.9390 ler=0.3575
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 073000] loss=0.106738 acc_masked=0.9427 ler=0.1762 elapsed=99.9s
[stage2 step 074000] loss=0.096535 acc_masked=0.9448 ler=0.2031 elapsed=98.1s
[stage2 step 075000] loss=0.102940 acc_masked=0.9427 ler=0.1762 elapsed=98.5s
[stage2 step 076000] loss=0.110807 acc_masked=0.9335 ler=0.1954 elapsed=98.0s
[eval stage2 @ step 076000] loss=0.479741 acc=0.9407 ler=0.3483
[checkpoint] saved model/curriculum_runs/stage2.pickle
[stage2 step 077000] loss=0.116970 acc_masked=0.9306 ler=0.2337 elapsed=100.1s
[stage2 step 078000] loss=0.087742 acc_masked=0.9420 ler=0.1762 elapsed=98.4s
[stage2 step 079000] loss=0.081341 acc_masked=0.9511 ler=0.1954 elapsed=98.3s
[stage2 step 080000] loss=0.080654 acc_masked=0.9593 ler=0.1418 elapsed=97.9s
[eval stage2 @ step 080000] loss=0.502466 acc=0.9381 ler=0.3541
[checkpoint] saved model/curriculum_runs/stage2.pickle
[multi-device] Adjusting stage3 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage3 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 3/7: stage3 (R1=2, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage3 step 000001] loss=0.068970 acc_masked=0.9661 ler=0.1149 elapsed=53.6s
[stage3 step 001000] loss=0.098004 acc_masked=0.9473 ler=0.1571 elapsed=93.5s
[stage3 step 002000] loss=0.085199 acc_masked=0.9563 ler=0.1379 elapsed=93.9s
[stage3 step 003000] loss=0.089674 acc_masked=0.9640 ler=0.1149 elapsed=93.9s
[stage3 step 004000] loss=0.077456 acc_masked=0.9656 ler=0.1034 elapsed=93.8s
[eval stage3 @ step 004000] loss=0.396580 acc=0.9519 ler=0.2915
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 005000] loss=0.061354 acc_masked=0.9663 ler=0.1034 elapsed=101.2s
[stage3 step 006000] loss=0.084992 acc_masked=0.9480 ler=0.1648 elapsed=94.0s
[stage3 step 007000] loss=0.091009 acc_masked=0.9565 ler=0.1533 elapsed=93.5s
[stage3 step 008000] loss=0.062508 acc_masked=0.9635 ler=0.1418 elapsed=94.3s
[eval stage3 @ step 008000] loss=0.389973 acc=0.9515 ler=0.2915
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 009000] loss=0.077616 acc_masked=0.9447 ler=0.2069 elapsed=95.6s
[stage3 step 010000] loss=0.073209 acc_masked=0.9656 ler=0.1073 elapsed=93.9s
[stage3 step 011000] loss=0.091630 acc_masked=0.9521 ler=0.1609 elapsed=94.1s
[stage3 step 012000] loss=0.093228 acc_masked=0.9496 ler=0.1686 elapsed=93.7s
[eval stage3 @ step 012000] loss=0.381452 acc=0.9537 ler=0.2871
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 013000] loss=0.078729 acc_masked=0.9550 ler=0.1609 elapsed=95.7s
[stage3 step 014000] loss=0.081223 acc_masked=0.9581 ler=0.1341 elapsed=94.0s
[stage3 step 015000] loss=0.107197 acc_masked=0.9480 ler=0.1533 elapsed=93.1s
[stage3 step 016000] loss=0.098091 acc_masked=0.9456 ler=0.1533 elapsed=93.5s
[eval stage3 @ step 016000] loss=0.382584 acc=0.9533 ler=0.2948
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 017000] loss=0.080132 acc_masked=0.9558 ler=0.1418 elapsed=95.8s
[stage3 step 018000] loss=0.075139 acc_masked=0.9618 ler=0.1341 elapsed=94.4s
[stage3 step 019000] loss=0.074940 acc_masked=0.9559 ler=0.1456 elapsed=94.2s
[stage3 step 020000] loss=0.087766 acc_masked=0.9507 ler=0.1762 elapsed=94.1s
[eval stage3 @ step 020000] loss=0.393508 acc=0.9524 ler=0.2895
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 021000] loss=0.100996 acc_masked=0.9488 ler=0.1609 elapsed=95.4s
[stage3 step 022000] loss=0.088175 acc_masked=0.9502 ler=0.1877 elapsed=93.7s
[stage3 step 023000] loss=0.096922 acc_masked=0.9594 ler=0.1341 elapsed=94.2s
[stage3 step 024000] loss=0.116538 acc_masked=0.9458 ler=0.1418 elapsed=93.8s
[eval stage3 @ step 024000] loss=0.395064 acc=0.9525 ler=0.2953
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 025000] loss=0.059322 acc_masked=0.9754 ler=0.0958 elapsed=95.7s
[stage3 step 026000] loss=0.109327 acc_masked=0.9451 ler=0.1724 elapsed=93.9s
[stage3 step 027000] loss=0.075529 acc_masked=0.9510 ler=0.1533 elapsed=93.8s
[stage3 step 028000] loss=0.094509 acc_masked=0.9532 ler=0.1456 elapsed=94.1s
[eval stage3 @ step 028000] loss=0.387634 acc=0.9536 ler=0.2898
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 029000] loss=0.055299 acc_masked=0.9748 ler=0.0996 elapsed=95.9s
[stage3 step 030000] loss=0.087201 acc_masked=0.9537 ler=0.1571 elapsed=94.6s
[stage3 step 031000] loss=0.099095 acc_masked=0.9505 ler=0.1418 elapsed=94.8s
[stage3 step 032000] loss=0.078474 acc_masked=0.9586 ler=0.1379 elapsed=92.8s
[eval stage3 @ step 032000] loss=0.404437 acc=0.9517 ler=0.2912
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 033000] loss=0.066604 acc_masked=0.9637 ler=0.1341 elapsed=93.6s
[stage3 step 034000] loss=0.078859 acc_masked=0.9580 ler=0.1341 elapsed=92.9s
[stage3 step 035000] loss=0.075936 acc_masked=0.9534 ler=0.1686 elapsed=92.0s
[stage3 step 036000] loss=0.082642 acc_masked=0.9471 ler=0.1533 elapsed=91.6s
[eval stage3 @ step 036000] loss=0.404018 acc=0.9524 ler=0.2886
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 037000] loss=0.083855 acc_masked=0.9568 ler=0.1303 elapsed=93.5s
[stage3 step 038000] loss=0.096174 acc_masked=0.9519 ler=0.1379 elapsed=91.8s
[stage3 step 039000] loss=0.069874 acc_masked=0.9679 ler=0.1264 elapsed=91.6s
[stage3 step 040000] loss=0.094490 acc_masked=0.9473 ler=0.1724 elapsed=91.2s
[eval stage3 @ step 040000] loss=0.407780 acc=0.9524 ler=0.2928
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 041000] loss=0.069880 acc_masked=0.9626 ler=0.1264 elapsed=93.4s
[stage3 step 042000] loss=0.111449 acc_masked=0.9438 ler=0.1571 elapsed=91.6s
[stage3 step 043000] loss=0.075249 acc_masked=0.9566 ler=0.1533 elapsed=91.2s
[stage3 step 044000] loss=0.071048 acc_masked=0.9656 ler=0.1188 elapsed=91.0s
[eval stage3 @ step 044000] loss=0.403637 acc=0.9528 ler=0.2877
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 045000] loss=0.124243 acc_masked=0.9459 ler=0.1379 elapsed=93.0s
[stage3 step 046000] loss=0.075033 acc_masked=0.9601 ler=0.1418 elapsed=91.3s
[stage3 step 047000] loss=0.078698 acc_masked=0.9542 ler=0.1571 elapsed=91.7s
[stage3 step 048000] loss=0.072563 acc_masked=0.9691 ler=0.1264 elapsed=91.6s
[eval stage3 @ step 048000] loss=0.412710 acc=0.9508 ler=0.2970
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 049000] loss=0.091920 acc_masked=0.9541 ler=0.1456 elapsed=93.0s
[stage3 step 050000] loss=0.087916 acc_masked=0.9577 ler=0.1379 elapsed=92.5s
[stage3 step 051000] loss=0.098749 acc_masked=0.9509 ler=0.1648 elapsed=91.8s
[stage3 step 052000] loss=0.072905 acc_masked=0.9626 ler=0.1226 elapsed=91.7s
[eval stage3 @ step 052000] loss=0.402107 acc=0.9530 ler=0.2851
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 053000] loss=0.095752 acc_masked=0.9539 ler=0.1533 elapsed=93.5s
[stage3 step 054000] loss=0.104768 acc_masked=0.9524 ler=0.1264 elapsed=91.4s
[stage3 step 055000] loss=0.088882 acc_masked=0.9503 ler=0.1609 elapsed=91.6s
[stage3 step 056000] loss=0.101654 acc_masked=0.9469 ler=0.1533 elapsed=91.6s
[eval stage3 @ step 056000] loss=0.382072 acc=0.9541 ler=0.2804
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 057000] loss=0.054633 acc_masked=0.9731 ler=0.1111 elapsed=93.7s
[stage3 step 058000] loss=0.089525 acc_masked=0.9539 ler=0.1609 elapsed=91.5s
[stage3 step 059000] loss=0.081782 acc_masked=0.9544 ler=0.1686 elapsed=91.5s
[stage3 step 060000] loss=0.082646 acc_masked=0.9596 ler=0.1418 elapsed=91.7s
[eval stage3 @ step 060000] loss=0.380847 acc=0.9535 ler=0.2916
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 061000] loss=0.074936 acc_masked=0.9572 ler=0.1379 elapsed=93.5s
[stage3 step 062000] loss=0.071399 acc_masked=0.9662 ler=0.0996 elapsed=91.5s
[stage3 step 063000] loss=0.089623 acc_masked=0.9484 ler=0.1648 elapsed=91.2s
[stage3 step 064000] loss=0.088504 acc_masked=0.9527 ler=0.1456 elapsed=91.5s
[eval stage3 @ step 064000] loss=0.401662 acc=0.9518 ler=0.2942
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 065000] loss=0.070190 acc_masked=0.9641 ler=0.1303 elapsed=93.2s
[stage3 step 066000] loss=0.058456 acc_masked=0.9658 ler=0.1303 elapsed=90.9s
[stage3 step 067000] loss=0.086767 acc_masked=0.9557 ler=0.1379 elapsed=91.3s
[stage3 step 068000] loss=0.086088 acc_masked=0.9550 ler=0.1533 elapsed=91.4s
[eval stage3 @ step 068000] loss=0.387596 acc=0.9549 ler=0.2854
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 069000] loss=0.081961 acc_masked=0.9585 ler=0.1379 elapsed=93.5s
[stage3 step 070000] loss=0.103785 acc_masked=0.9471 ler=0.1724 elapsed=91.8s
[stage3 step 071000] loss=0.099108 acc_masked=0.9467 ler=0.1609 elapsed=91.7s
[stage3 step 072000] loss=0.098770 acc_masked=0.9561 ler=0.1264 elapsed=91.5s
[eval stage3 @ step 072000] loss=0.394508 acc=0.9534 ler=0.2887
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 073000] loss=0.075062 acc_masked=0.9608 ler=0.1264 elapsed=93.7s
[stage3 step 074000] loss=0.080926 acc_masked=0.9504 ler=0.1648 elapsed=91.8s
[stage3 step 075000] loss=0.128653 acc_masked=0.9359 ler=0.1801 elapsed=91.8s
[stage3 step 076000] loss=0.071602 acc_masked=0.9640 ler=0.1226 elapsed=92.3s
[eval stage3 @ step 076000] loss=0.419044 acc=0.9511 ler=0.2953
[checkpoint] saved model/curriculum_runs/stage3.pickle
[stage3 step 077000] loss=0.086105 acc_masked=0.9574 ler=0.1188 elapsed=95.6s
[stage3 step 078000] loss=0.089790 acc_masked=0.9553 ler=0.1418 elapsed=93.5s
[stage3 step 079000] loss=0.091749 acc_masked=0.9536 ler=0.1379 elapsed=93.9s
[stage3 step 080000] loss=0.086876 acc_masked=0.9558 ler=0.1533 elapsed=93.9s
[eval stage3 @ step 080000] loss=0.409772 acc=0.9527 ler=0.2912
[checkpoint] saved model/curriculum_runs/stage3.pickle
[multi-device] Adjusting stage4 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage4 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 4/7: stage4 (R1=3, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage4 step 000001] loss=0.069939 acc_masked=0.9711 ler=0.1149 elapsed=47.8s
[stage4 step 001000] loss=0.079890 acc_masked=0.9617 ler=0.1226 elapsed=86.6s
[stage4 step 002000] loss=0.058672 acc_masked=0.9772 ler=0.1034 elapsed=86.9s
[stage4 step 003000] loss=0.064200 acc_masked=0.9753 ler=0.0920 elapsed=86.9s
[stage4 step 004000] loss=0.069728 acc_masked=0.9696 ler=0.1226 elapsed=87.1s
[eval stage4 @ step 004000] loss=0.280883 acc=0.9661 ler=0.2233
[checkpoint] saved model/curriculum_runs/stage4.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage4 step 005000] loss=0.077960 acc_masked=0.9645 ler=0.1226 elapsed=94.5s
[stage4 step 006000] loss=0.062957 acc_masked=0.9742 ler=0.0843 elapsed=87.4s
[stage4 step 007000] loss=0.057461 acc_masked=0.9766 ler=0.0843 elapsed=87.8s
[stage4 step 008000] loss=0.070665 acc_masked=0.9734 ler=0.0881 elapsed=87.1s
[eval stage4 @ step 008000] loss=0.285865 acc=0.9669 ler=0.2153
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 009000] loss=0.082941 acc_masked=0.9708 ler=0.1149 elapsed=89.1s
[stage4 step 010000] loss=0.096723 acc_masked=0.9634 ler=0.1034 elapsed=87.5s
[stage4 step 011000] loss=0.067489 acc_masked=0.9698 ler=0.0996 elapsed=87.1s
[stage4 step 012000] loss=0.061137 acc_masked=0.9768 ler=0.0843 elapsed=87.3s
[eval stage4 @ step 012000] loss=0.284001 acc=0.9670 ler=0.2167
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 013000] loss=0.090988 acc_masked=0.9612 ler=0.1264 elapsed=89.6s
[stage4 step 014000] loss=0.041296 acc_masked=0.9849 ler=0.0651 elapsed=87.2s
[stage4 step 015000] loss=0.061824 acc_masked=0.9755 ler=0.0958 elapsed=87.5s
[stage4 step 016000] loss=0.087936 acc_masked=0.9587 ler=0.1341 elapsed=87.3s
[eval stage4 @ step 016000] loss=0.282796 acc=0.9678 ler=0.2144
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 017000] loss=0.064947 acc_masked=0.9719 ler=0.1073 elapsed=89.0s
[stage4 step 018000] loss=0.068578 acc_masked=0.9730 ler=0.1034 elapsed=87.2s
[stage4 step 019000] loss=0.077753 acc_masked=0.9653 ler=0.1226 elapsed=87.2s
[stage4 step 020000] loss=0.072678 acc_masked=0.9698 ler=0.0958 elapsed=87.2s
[eval stage4 @ step 020000] loss=0.298336 acc=0.9659 ler=0.2224
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 021000] loss=0.064305 acc_masked=0.9787 ler=0.0728 elapsed=89.2s
[stage4 step 022000] loss=0.085385 acc_masked=0.9647 ler=0.1188 elapsed=86.4s
[stage4 step 023000] loss=0.075831 acc_masked=0.9700 ler=0.1264 elapsed=87.3s
[stage4 step 024000] loss=0.082664 acc_masked=0.9651 ler=0.1341 elapsed=87.2s
[eval stage4 @ step 024000] loss=0.299531 acc=0.9665 ler=0.2177
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 025000] loss=0.080726 acc_masked=0.9636 ler=0.1264 elapsed=88.8s
[stage4 step 026000] loss=0.084106 acc_masked=0.9715 ler=0.1111 elapsed=87.5s
[stage4 step 027000] loss=0.095796 acc_masked=0.9548 ler=0.1456 elapsed=86.9s
[stage4 step 028000] loss=0.104030 acc_masked=0.9579 ler=0.1341 elapsed=87.2s
[eval stage4 @ step 028000] loss=0.302060 acc=0.9651 ler=0.2274
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 029000] loss=0.067876 acc_masked=0.9696 ler=0.1188 elapsed=88.3s
[stage4 step 030000] loss=0.089106 acc_masked=0.9642 ler=0.1456 elapsed=87.1s
[stage4 step 031000] loss=0.070648 acc_masked=0.9747 ler=0.0843 elapsed=87.5s
[stage4 step 032000] loss=0.063596 acc_masked=0.9702 ler=0.1226 elapsed=87.7s
[eval stage4 @ step 032000] loss=0.288136 acc=0.9680 ler=0.2108
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 033000] loss=0.080790 acc_masked=0.9687 ler=0.1188 elapsed=89.3s
[stage4 step 034000] loss=0.068297 acc_masked=0.9676 ler=0.1341 elapsed=87.5s
[stage4 step 035000] loss=0.085785 acc_masked=0.9664 ler=0.1149 elapsed=87.2s
[stage4 step 036000] loss=0.053775 acc_masked=0.9757 ler=0.0958 elapsed=87.3s
[eval stage4 @ step 036000] loss=0.293867 acc=0.9676 ler=0.2122
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 037000] loss=0.079815 acc_masked=0.9728 ler=0.0881 elapsed=88.7s
[stage4 step 038000] loss=0.076853 acc_masked=0.9676 ler=0.1034 elapsed=87.6s
[stage4 step 039000] loss=0.073961 acc_masked=0.9672 ler=0.1188 elapsed=87.3s
[stage4 step 040000] loss=0.058777 acc_masked=0.9781 ler=0.0958 elapsed=87.0s
[eval stage4 @ step 040000] loss=0.282477 acc=0.9669 ler=0.2186
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 041000] loss=0.082783 acc_masked=0.9687 ler=0.1149 elapsed=88.9s
[stage4 step 042000] loss=0.071301 acc_masked=0.9706 ler=0.1149 elapsed=87.6s
[stage4 step 043000] loss=0.087866 acc_masked=0.9664 ler=0.1149 elapsed=87.1s
[stage4 step 044000] loss=0.065818 acc_masked=0.9679 ler=0.1303 elapsed=87.8s
[eval stage4 @ step 044000] loss=0.303356 acc=0.9667 ler=0.2149
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 045000] loss=0.084797 acc_masked=0.9673 ler=0.1264 elapsed=88.8s
[stage4 step 046000] loss=0.108528 acc_masked=0.9617 ler=0.1188 elapsed=87.4s
[stage4 step 047000] loss=0.056683 acc_masked=0.9766 ler=0.0920 elapsed=87.5s
[stage4 step 048000] loss=0.098507 acc_masked=0.9606 ler=0.1724 elapsed=87.3s
[eval stage4 @ step 048000] loss=0.295583 acc=0.9672 ler=0.2156
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 049000] loss=0.068046 acc_masked=0.9722 ler=0.1188 elapsed=89.4s
[stage4 step 050000] loss=0.082825 acc_masked=0.9608 ler=0.1303 elapsed=87.5s
[stage4 step 051000] loss=0.064457 acc_masked=0.9687 ler=0.1264 elapsed=87.1s
[stage4 step 052000] loss=0.069215 acc_masked=0.9702 ler=0.1188 elapsed=87.4s
[eval stage4 @ step 052000] loss=0.300487 acc=0.9663 ler=0.2180
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 053000] loss=0.067631 acc_masked=0.9681 ler=0.1149 elapsed=89.3s
[stage4 step 054000] loss=0.096254 acc_masked=0.9606 ler=0.1341 elapsed=87.1s
[stage4 step 055000] loss=0.073696 acc_masked=0.9706 ler=0.1111 elapsed=87.6s
[stage4 step 056000] loss=0.069025 acc_masked=0.9752 ler=0.0920 elapsed=87.1s
[eval stage4 @ step 056000] loss=0.303725 acc=0.9660 ler=0.2204
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 057000] loss=0.085657 acc_masked=0.9668 ler=0.1226 elapsed=89.3s
[stage4 step 058000] loss=0.096831 acc_masked=0.9640 ler=0.1226 elapsed=87.3s
[stage4 step 059000] loss=0.074767 acc_masked=0.9636 ler=0.1226 elapsed=87.0s
[stage4 step 060000] loss=0.069952 acc_masked=0.9728 ler=0.1034 elapsed=86.9s
[eval stage4 @ step 060000] loss=0.284925 acc=0.9671 ler=0.2117
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 061000] loss=0.068210 acc_masked=0.9734 ler=0.1149 elapsed=88.7s
[stage4 step 062000] loss=0.075658 acc_masked=0.9645 ler=0.1226 elapsed=86.7s
[stage4 step 063000] loss=0.080222 acc_masked=0.9632 ler=0.1303 elapsed=87.5s
[stage4 step 064000] loss=0.065934 acc_masked=0.9643 ler=0.1149 elapsed=87.5s
[eval stage4 @ step 064000] loss=0.297364 acc=0.9659 ler=0.2225
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 065000] loss=0.074527 acc_masked=0.9698 ler=0.1188 elapsed=89.9s
[stage4 step 066000] loss=0.069748 acc_masked=0.9732 ler=0.1149 elapsed=87.9s
[stage4 step 067000] loss=0.069664 acc_masked=0.9717 ler=0.0996 elapsed=86.7s
[stage4 step 068000] loss=0.057617 acc_masked=0.9772 ler=0.0728 elapsed=86.7s
[eval stage4 @ step 068000] loss=0.304142 acc=0.9664 ler=0.2218
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 069000] loss=0.071847 acc_masked=0.9726 ler=0.1034 elapsed=89.2s
[stage4 step 070000] loss=0.079654 acc_masked=0.9664 ler=0.1418 elapsed=87.6s
[stage4 step 071000] loss=0.056003 acc_masked=0.9819 ler=0.0843 elapsed=87.7s
[stage4 step 072000] loss=0.084829 acc_masked=0.9637 ler=0.1226 elapsed=87.6s
[eval stage4 @ step 072000] loss=0.294021 acc=0.9672 ler=0.2163
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 073000] loss=0.097617 acc_masked=0.9596 ler=0.1341 elapsed=89.4s
[stage4 step 074000] loss=0.080027 acc_masked=0.9711 ler=0.1111 elapsed=87.6s
[stage4 step 075000] loss=0.059131 acc_masked=0.9736 ler=0.1073 elapsed=87.7s
[stage4 step 076000] loss=0.090702 acc_masked=0.9664 ler=0.1188 elapsed=87.3s
[eval stage4 @ step 076000] loss=0.295596 acc=0.9668 ler=0.2140
[checkpoint] saved model/curriculum_runs/stage4.pickle
[stage4 step 077000] loss=0.067194 acc_masked=0.9718 ler=0.1034 elapsed=88.9s
[stage4 step 078000] loss=0.077951 acc_masked=0.9681 ler=0.1226 elapsed=87.2s
[stage4 step 079000] loss=0.096298 acc_masked=0.9630 ler=0.1303 elapsed=86.8s
[stage4 step 080000] loss=0.080424 acc_masked=0.9659 ler=0.1418 elapsed=87.6s
[eval stage4 @ step 080000] loss=0.296321 acc=0.9672 ler=0.2146
[checkpoint] saved model/curriculum_runs/stage4.pickle
[multi-device] Adjusting stage5 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage5 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 5/7: stage5 (R1=4, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage5 step 000001] loss=0.059211 acc_masked=0.9818 ler=0.0728 elapsed=41.0s
[stage5 step 001000] loss=0.067372 acc_masked=0.9756 ler=0.0920 elapsed=80.5s
[stage5 step 002000] loss=0.054068 acc_masked=0.9852 ler=0.0613 elapsed=80.7s
[stage5 step 003000] loss=0.045232 acc_masked=0.9866 ler=0.0460 elapsed=80.8s
[stage5 step 004000] loss=0.051585 acc_masked=0.9820 ler=0.0651 elapsed=80.7s
[eval stage5 @ step 004000] loss=0.175456 acc=0.9800 ler=0.1397
[checkpoint] saved model/curriculum_runs/stage5.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage5 step 005000] loss=0.058965 acc_masked=0.9818 ler=0.0728 elapsed=87.4s
[stage5 step 006000] loss=0.065475 acc_masked=0.9837 ler=0.0536 elapsed=81.0s
[stage5 step 007000] loss=0.052484 acc_masked=0.9818 ler=0.0728 elapsed=81.1s
[stage5 step 008000] loss=0.039517 acc_masked=0.9890 ler=0.0498 elapsed=80.9s
[eval stage5 @ step 008000] loss=0.176068 acc=0.9804 ler=0.1378
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 009000] loss=0.063403 acc_masked=0.9756 ler=0.0958 elapsed=82.1s
[stage5 step 010000] loss=0.056420 acc_masked=0.9823 ler=0.0690 elapsed=80.0s
[stage5 step 011000] loss=0.079632 acc_masked=0.9745 ler=0.0958 elapsed=80.3s
[stage5 step 012000] loss=0.051235 acc_masked=0.9852 ler=0.0651 elapsed=81.1s
[eval stage5 @ step 012000] loss=0.179085 acc=0.9804 ler=0.1319
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 013000] loss=0.050400 acc_masked=0.9847 ler=0.0613 elapsed=83.2s
[stage5 step 014000] loss=0.035826 acc_masked=0.9899 ler=0.0498 elapsed=80.8s
[stage5 step 015000] loss=0.061382 acc_masked=0.9789 ler=0.0958 elapsed=80.4s
[stage5 step 016000] loss=0.054093 acc_masked=0.9818 ler=0.0805 elapsed=80.3s
[eval stage5 @ step 016000] loss=0.179855 acc=0.9804 ler=0.1370
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 017000] loss=0.047615 acc_masked=0.9875 ler=0.0651 elapsed=82.4s
[stage5 step 018000] loss=0.047989 acc_masked=0.9887 ler=0.0421 elapsed=80.6s
[stage5 step 019000] loss=0.059144 acc_masked=0.9804 ler=0.0613 elapsed=80.9s
[stage5 step 020000] loss=0.052132 acc_masked=0.9796 ler=0.0996 elapsed=80.5s
[eval stage5 @ step 020000] loss=0.176319 acc=0.9808 ler=0.1348
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 021000] loss=0.050077 acc_masked=0.9863 ler=0.0575 elapsed=82.2s
[stage5 step 022000] loss=0.061021 acc_masked=0.9780 ler=0.0996 elapsed=81.0s
[stage5 step 023000] loss=0.039156 acc_masked=0.9879 ler=0.0460 elapsed=80.7s
[stage5 step 024000] loss=0.056225 acc_masked=0.9784 ler=0.0805 elapsed=80.4s
[eval stage5 @ step 024000] loss=0.174273 acc=0.9804 ler=0.1352
[checkpoint] saved model/curriculum_runs/stage5.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage5 step 025000] loss=0.071190 acc_masked=0.9784 ler=0.0690 elapsed=82.6s
[stage5 step 026000] loss=0.033310 acc_masked=0.9899 ler=0.0498 elapsed=81.1s
[stage5 step 027000] loss=0.062339 acc_masked=0.9808 ler=0.0766 elapsed=82.1s
[stage5 step 028000] loss=0.078703 acc_masked=0.9761 ler=0.0958 elapsed=81.1s
[eval stage5 @ step 028000] loss=0.186275 acc=0.9800 ler=0.1395
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 029000] loss=0.054217 acc_masked=0.9832 ler=0.0690 elapsed=82.5s
[stage5 step 030000] loss=0.068104 acc_masked=0.9804 ler=0.0728 elapsed=81.9s
[stage5 step 031000] loss=0.057026 acc_masked=0.9789 ler=0.0881 elapsed=81.4s
[stage5 step 032000] loss=0.056765 acc_masked=0.9799 ler=0.0690 elapsed=80.9s
[eval stage5 @ step 032000] loss=0.181519 acc=0.9803 ler=0.1367
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 033000] loss=0.050808 acc_masked=0.9834 ler=0.0728 elapsed=82.8s
[stage5 step 034000] loss=0.054197 acc_masked=0.9832 ler=0.0651 elapsed=81.0s
[stage5 step 035000] loss=0.067148 acc_masked=0.9794 ler=0.0728 elapsed=80.8s
[stage5 step 036000] loss=0.065615 acc_masked=0.9756 ler=0.0958 elapsed=80.7s
[eval stage5 @ step 036000] loss=0.168029 acc=0.9810 ler=0.1340
[checkpoint] saved model/curriculum_runs/stage5.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage5 step 037000] loss=0.070423 acc_masked=0.9813 ler=0.0651 elapsed=82.6s
[stage5 step 038000] loss=0.053439 acc_masked=0.9837 ler=0.0651 elapsed=80.7s
[stage5 step 039000] loss=0.057466 acc_masked=0.9834 ler=0.0575 elapsed=80.7s
[stage5 step 040000] loss=0.042783 acc_masked=0.9858 ler=0.0690 elapsed=80.7s
[eval stage5 @ step 040000] loss=0.178359 acc=0.9808 ler=0.1329
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 041000] loss=0.041617 acc_masked=0.9875 ler=0.0498 elapsed=82.3s
[stage5 step 042000] loss=0.056790 acc_masked=0.9828 ler=0.0728 elapsed=80.6s
[stage5 step 043000] loss=0.071400 acc_masked=0.9784 ler=0.0728 elapsed=81.3s
[stage5 step 044000] loss=0.060265 acc_masked=0.9815 ler=0.0766 elapsed=81.1s
[eval stage5 @ step 044000] loss=0.175363 acc=0.9812 ler=0.1309
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 045000] loss=0.041788 acc_masked=0.9875 ler=0.0460 elapsed=82.4s
[stage5 step 046000] loss=0.050750 acc_masked=0.9842 ler=0.0651 elapsed=81.0s
[stage5 step 047000] loss=0.074731 acc_masked=0.9746 ler=0.0958 elapsed=80.7s
[stage5 step 048000] loss=0.079199 acc_masked=0.9713 ler=0.0996 elapsed=80.9s
[eval stage5 @ step 048000] loss=0.183583 acc=0.9803 ler=0.1371
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 049000] loss=0.051200 acc_masked=0.9823 ler=0.0728 elapsed=82.7s
[stage5 step 050000] loss=0.057978 acc_masked=0.9828 ler=0.0651 elapsed=81.0s
[stage5 step 051000] loss=0.067213 acc_masked=0.9823 ler=0.0651 elapsed=80.7s
[stage5 step 052000] loss=0.079756 acc_masked=0.9751 ler=0.0843 elapsed=80.6s
[eval stage5 @ step 052000] loss=0.172959 acc=0.9813 ler=0.1349
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 053000] loss=0.050336 acc_masked=0.9837 ler=0.0728 elapsed=83.0s
[stage5 step 054000] loss=0.057395 acc_masked=0.9769 ler=0.0920 elapsed=81.5s
[stage5 step 055000] loss=0.076345 acc_masked=0.9751 ler=0.0958 elapsed=81.0s
[stage5 step 056000] loss=0.072645 acc_masked=0.9789 ler=0.0805 elapsed=81.0s
[eval stage5 @ step 056000] loss=0.180624 acc=0.9803 ler=0.1348
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 057000] loss=0.051441 acc_masked=0.9780 ler=0.0805 elapsed=82.4s
[stage5 step 058000] loss=0.059016 acc_masked=0.9847 ler=0.0460 elapsed=81.1s
[stage5 step 059000] loss=0.072130 acc_masked=0.9775 ler=0.0843 elapsed=80.9s
[stage5 step 060000] loss=0.036902 acc_masked=0.9856 ler=0.0575 elapsed=80.9s
[eval stage5 @ step 060000] loss=0.169339 acc=0.9813 ler=0.1298
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 061000] loss=0.070507 acc_masked=0.9780 ler=0.0881 elapsed=82.5s
[stage5 step 062000] loss=0.033408 acc_masked=0.9909 ler=0.0307 elapsed=80.6s
[stage5 step 063000] loss=0.069941 acc_masked=0.9762 ler=0.0958 elapsed=80.5s
[stage5 step 064000] loss=0.058339 acc_masked=0.9813 ler=0.0651 elapsed=80.8s
[eval stage5 @ step 064000] loss=0.183740 acc=0.9805 ler=0.1363
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 065000] loss=0.044074 acc_masked=0.9871 ler=0.0536 elapsed=82.3s
[stage5 step 066000] loss=0.081060 acc_masked=0.9770 ler=0.0843 elapsed=80.5s
[stage5 step 067000] loss=0.044069 acc_masked=0.9866 ler=0.0575 elapsed=80.4s
[stage5 step 068000] loss=0.084380 acc_masked=0.9722 ler=0.1034 elapsed=81.2s
[eval stage5 @ step 068000] loss=0.188287 acc=0.9803 ler=0.1406
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 069000] loss=0.043945 acc_masked=0.9840 ler=0.0651 elapsed=82.1s
[stage5 step 070000] loss=0.068630 acc_masked=0.9737 ler=0.1111 elapsed=80.5s
[stage5 step 071000] loss=0.047911 acc_masked=0.9852 ler=0.0498 elapsed=80.3s
[stage5 step 072000] loss=0.049125 acc_masked=0.9832 ler=0.0690 elapsed=80.3s
[eval stage5 @ step 072000] loss=0.192598 acc=0.9799 ler=0.1402
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 073000] loss=0.050650 acc_masked=0.9828 ler=0.0651 elapsed=82.1s
[stage5 step 074000] loss=0.031689 acc_masked=0.9909 ler=0.0421 elapsed=80.4s
[stage5 step 075000] loss=0.042625 acc_masked=0.9856 ler=0.0575 elapsed=80.6s
[stage5 step 076000] loss=0.056260 acc_masked=0.9804 ler=0.0690 elapsed=81.0s
[eval stage5 @ step 076000] loss=0.170408 acc=0.9815 ler=0.1274
[checkpoint] saved model/curriculum_runs/stage5.pickle
[stage5 step 077000] loss=0.072610 acc_masked=0.9753 ler=0.0958 elapsed=82.3s
[stage5 step 078000] loss=0.060028 acc_masked=0.9804 ler=0.0805 elapsed=80.7s
[stage5 step 079000] loss=0.064896 acc_masked=0.9807 ler=0.0690 elapsed=80.7s
[stage5 step 080000] loss=0.056829 acc_masked=0.9832 ler=0.0690 elapsed=81.0s
[eval stage5 @ step 080000] loss=0.182387 acc=0.9804 ler=0.1385
[checkpoint] saved model/curriculum_runs/stage5.pickle
[multi-device] Adjusting stage6 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage6 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 6/7: stage6 (R1=5, R2=6, steps=80000, lr=0.0001, batch_size=261, eval_batch_size=2049) ===
[stage6 step 000001] loss=0.031723 acc_masked=0.9930 ler=0.0345 elapsed=36.0s
[stage6 step 001000] loss=0.026408 acc_masked=0.9939 ler=0.0307 elapsed=74.7s
[stage6 step 002000] loss=0.032380 acc_masked=0.9898 ler=0.0421 elapsed=75.4s
[stage6 step 003000] loss=0.031830 acc_masked=0.9911 ler=0.0345 elapsed=75.7s
[stage6 step 004000] loss=0.022868 acc_masked=0.9923 ler=0.0345 elapsed=75.9s
[eval stage6 @ step 004000] loss=0.058195 acc=0.9927 ler=0.0583
[checkpoint] saved model/curriculum_runs/stage6.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage6 step 005000] loss=0.030343 acc_masked=0.9936 ler=0.0307 elapsed=81.6s
[stage6 step 006000] loss=0.031196 acc_masked=0.9936 ler=0.0268 elapsed=75.0s
[stage6 step 007000] loss=0.017402 acc_masked=0.9923 ler=0.0268 elapsed=74.8s
[stage6 step 008000] loss=0.030514 acc_masked=0.9930 ler=0.0345 elapsed=75.1s
[eval stage6 @ step 008000] loss=0.055012 acc=0.9930 ler=0.0527
[checkpoint] saved model/curriculum_runs/stage6.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage6 step 009000] loss=0.020773 acc_masked=0.9949 ler=0.0192 elapsed=76.9s
[stage6 step 010000] loss=0.018669 acc_masked=0.9962 ler=0.0192 elapsed=74.9s
[stage6 step 011000] loss=0.043892 acc_masked=0.9891 ler=0.0460 elapsed=75.6s
[stage6 step 012000] loss=0.011324 acc_masked=0.9974 ler=0.0115 elapsed=74.8s
[eval stage6 @ step 012000] loss=0.058008 acc=0.9927 ler=0.0555
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 013000] loss=0.033429 acc_masked=0.9923 ler=0.0383 elapsed=77.1s
[stage6 step 014000] loss=0.028809 acc_masked=0.9923 ler=0.0307 elapsed=75.7s
[stage6 step 015000] loss=0.046682 acc_masked=0.9885 ler=0.0575 elapsed=75.8s
[stage6 step 016000] loss=0.012860 acc_masked=0.9981 ler=0.0077 elapsed=75.7s
[eval stage6 @ step 016000] loss=0.058460 acc=0.9931 ler=0.0523
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 017000] loss=0.027053 acc_masked=0.9914 ler=0.0421 elapsed=77.3s
[stage6 step 018000] loss=0.043904 acc_masked=0.9885 ler=0.0613 elapsed=76.1s
[stage6 step 019000] loss=0.029316 acc_masked=0.9930 ler=0.0345 elapsed=75.4s
[stage6 step 020000] loss=0.026035 acc_masked=0.9936 ler=0.0268 elapsed=75.5s
[eval stage6 @ step 020000] loss=0.053228 acc=0.9932 ler=0.0534
[checkpoint] saved model/curriculum_runs/stage6.pickle
[checkpoint] saved model/curriculum_runs/best.pickle
[stage6 step 021000] loss=0.014129 acc_masked=0.9978 ler=0.0153 elapsed=77.2s
[stage6 step 022000] loss=0.014877 acc_masked=0.9952 ler=0.0192 elapsed=75.7s
[stage6 step 023000] loss=0.034345 acc_masked=0.9936 ler=0.0268 elapsed=75.6s
[stage6 step 024000] loss=0.039009 acc_masked=0.9904 ler=0.0498 elapsed=75.4s
[eval stage6 @ step 024000] loss=0.054202 acc=0.9932 ler=0.0523
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 025000] loss=0.033405 acc_masked=0.9923 ler=0.0307 elapsed=76.6s
[stage6 step 026000] loss=0.033606 acc_masked=0.9898 ler=0.0421 elapsed=75.0s
[stage6 step 027000] loss=0.020709 acc_masked=0.9917 ler=0.0345 elapsed=75.4s
[stage6 step 028000] loss=0.028389 acc_masked=0.9907 ler=0.0383 elapsed=75.7s
[eval stage6 @ step 028000] loss=0.058410 acc=0.9928 ler=0.0531
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 029000] loss=0.008810 acc_masked=0.9981 ler=0.0115 elapsed=77.2s
[stage6 step 030000] loss=0.035586 acc_masked=0.9930 ler=0.0345 elapsed=75.5s
[stage6 step 031000] loss=0.022947 acc_masked=0.9946 ler=0.0230 elapsed=76.0s
[stage6 step 032000] loss=0.024797 acc_masked=0.9943 ler=0.0307 elapsed=75.5s
[eval stage6 @ step 032000] loss=0.061293 acc=0.9928 ler=0.0542
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 033000] loss=0.018786 acc_masked=0.9949 ler=0.0192 elapsed=77.1s
[stage6 step 034000] loss=0.016318 acc_masked=0.9955 ler=0.0192 elapsed=75.5s
[stage6 step 035000] loss=0.025663 acc_masked=0.9930 ler=0.0345 elapsed=75.7s
[stage6 step 036000] loss=0.017292 acc_masked=0.9955 ler=0.0192 elapsed=75.7s
[eval stage6 @ step 036000] loss=0.054148 acc=0.9933 ler=0.0525
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 037000] loss=0.014269 acc_masked=0.9978 ler=0.0153 elapsed=77.8s
[stage6 step 038000] loss=0.029195 acc_masked=0.9943 ler=0.0230 elapsed=75.5s
[stage6 step 039000] loss=0.013036 acc_masked=0.9974 ler=0.0153 elapsed=75.5s
[stage6 step 040000] loss=0.014611 acc_masked=0.9955 ler=0.0268 elapsed=75.2s
[eval stage6 @ step 040000] loss=0.061893 acc=0.9932 ler=0.0512
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 041000] loss=0.034809 acc_masked=0.9914 ler=0.0345 elapsed=77.0s
[stage6 step 042000] loss=0.021952 acc_masked=0.9955 ler=0.0268 elapsed=75.9s
[stage6 step 043000] loss=0.043991 acc_masked=0.9879 ler=0.0498 elapsed=75.8s
[stage6 step 044000] loss=0.024672 acc_masked=0.9923 ler=0.0307 elapsed=75.6s
[eval stage6 @ step 044000] loss=0.071288 acc=0.9920 ler=0.0597
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 045000] loss=0.020373 acc_masked=0.9958 ler=0.0230 elapsed=76.8s
[stage6 step 046000] loss=0.025628 acc_masked=0.9933 ler=0.0345 elapsed=75.3s
[stage6 step 047000] loss=0.032820 acc_masked=0.9914 ler=0.0345 elapsed=75.8s
[stage6 step 048000] loss=0.028028 acc_masked=0.9936 ler=0.0268 elapsed=75.8s
[eval stage6 @ step 048000] loss=0.068152 acc=0.9926 ler=0.0564
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 049000] loss=0.011226 acc_masked=0.9962 ler=0.0192 elapsed=77.2s
[stage6 step 050000] loss=0.021757 acc_masked=0.9936 ler=0.0268 elapsed=75.4s
[stage6 step 051000] loss=0.015289 acc_masked=0.9955 ler=0.0268 elapsed=76.8s
[stage6 step 052000] loss=0.046908 acc_masked=0.9872 ler=0.0651 elapsed=76.4s
[eval stage6 @ step 052000] loss=0.053452 acc=0.9933 ler=0.0530
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 053000] loss=0.030118 acc_masked=0.9930 ler=0.0345 elapsed=77.4s
[stage6 step 054000] loss=0.023635 acc_masked=0.9949 ler=0.0230 elapsed=75.6s
[stage6 step 055000] loss=0.017417 acc_masked=0.9968 ler=0.0192 elapsed=75.4s
[stage6 step 056000] loss=0.025358 acc_masked=0.9914 ler=0.0421 elapsed=75.4s
[eval stage6 @ step 056000] loss=0.061818 acc=0.9929 ler=0.0523
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 057000] loss=0.012573 acc_masked=0.9962 ler=0.0192 elapsed=77.4s
[stage6 step 058000] loss=0.016768 acc_masked=0.9949 ler=0.0307 elapsed=76.4s
[stage6 step 059000] loss=0.021535 acc_masked=0.9943 ler=0.0345 elapsed=78.0s
[stage6 step 060000] loss=0.025058 acc_masked=0.9930 ler=0.0383 elapsed=75.6s
[eval stage6 @ step 060000] loss=0.068646 acc=0.9924 ler=0.0584
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 061000] loss=0.020906 acc_masked=0.9943 ler=0.0268 elapsed=77.3s
[stage6 step 062000] loss=0.024798 acc_masked=0.9930 ler=0.0345 elapsed=75.5s
[stage6 step 063000] loss=0.009697 acc_masked=0.9981 ler=0.0115 elapsed=75.3s
[stage6 step 064000] loss=0.024460 acc_masked=0.9949 ler=0.0307 elapsed=75.4s
[eval stage6 @ step 064000] loss=0.066013 acc=0.9928 ler=0.0558
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 065000] loss=0.016458 acc_masked=0.9939 ler=0.0268 elapsed=77.2s
[stage6 step 066000] loss=0.015313 acc_masked=0.9962 ler=0.0192 elapsed=75.5s
[stage6 step 067000] loss=0.021084 acc_masked=0.9933 ler=0.0383 elapsed=75.7s
[stage6 step 068000] loss=0.017773 acc_masked=0.9958 ler=0.0268 elapsed=75.6s
[eval stage6 @ step 068000] loss=0.063736 acc=0.9925 ler=0.0571
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 069000] loss=0.015738 acc_masked=0.9968 ler=0.0192 elapsed=76.8s
[stage6 step 070000] loss=0.023943 acc_masked=0.9936 ler=0.0268 elapsed=75.3s
[stage6 step 071000] loss=0.018055 acc_masked=0.9965 ler=0.0153 elapsed=75.9s
[stage6 step 072000] loss=0.024469 acc_masked=0.9933 ler=0.0383 elapsed=75.6s
[eval stage6 @ step 072000] loss=0.059417 acc=0.9929 ler=0.0551
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 073000] loss=0.022824 acc_masked=0.9930 ler=0.0383 elapsed=76.7s
[stage6 step 074000] loss=0.009825 acc_masked=0.9965 ler=0.0192 elapsed=75.3s
[stage6 step 075000] loss=0.029361 acc_masked=0.9936 ler=0.0307 elapsed=75.5s
[stage6 step 076000] loss=0.017323 acc_masked=0.9949 ler=0.0268 elapsed=75.5s
[eval stage6 @ step 076000] loss=0.060488 acc=0.9931 ler=0.0539
[checkpoint] saved model/curriculum_runs/stage6.pickle
[stage6 step 077000] loss=0.017248 acc_masked=0.9949 ler=0.0268 elapsed=77.0s
[stage6 step 078000] loss=0.029378 acc_masked=0.9930 ler=0.0421 elapsed=74.8s
[stage6 step 079000] loss=0.023066 acc_masked=0.9936 ler=0.0345 elapsed=75.0s
[stage6 step 080000] loss=0.023342 acc_masked=0.9933 ler=0.0345 elapsed=75.8s
[eval stage6 @ step 080000] loss=0.055506 acc=0.9934 ler=0.0522
[checkpoint] saved model/curriculum_runs/stage6.pickle
[multi-device] Adjusting stage7 batch_size from 260 to 261 to divide evenly across 3 devices.
[multi-device] Adjusting stage7 eval_batch_size from 2048 to 2049 to divide evenly across 3 devices.

=== Stage 7/7: stage7 (R1=6, R2=6, steps=720000, lr=5e-05, batch_size=261, eval_batch_size=2049) ===
[stage7 step 000001] loss=0.004474 acc_masked=0.9974 ler=0.0077 elapsed=32.2s
[stage7 step 005000] loss=0.000221 acc_masked=1.0000 ler=0.0000 elapsed=355.4s
[checkpoint] saved model/curriculum_runs/stage7_step005000_ler0.pickle
[early-stop] Saved stage7_step005000_ler0.pickle after training ler=0.
[early-stop] stage7 step 005000 reached training ler=0. Stopping training.
[checkpoint] saved model/curriculum_runs/best.pickle
